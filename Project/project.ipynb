{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28026\n"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with open('docs_titles.tsv') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "        data = line.strip().split('\\t', 1)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = title\n",
    "print (len(doc_to_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Stemmer\n",
    "import re\n",
    "stemmer = Stemmer.Stemmer('russian')\n",
    "train_data = pd.read_csv('train_groups.csv')\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(train_data)):\n",
    "    new_doc = train_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    target = new_doc['target']\n",
    "    text = doc_to_title[doc_id].lower()\n",
    "    title = ' '.join(list(map(stemmer.stemWord, text.split())))\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 21) (11690,) (11690,)\n"
     ]
    }
   ],
   "source": [
    "y_train = []\n",
    "X_train = []\n",
    "groups_train = []\n",
    "for new_group in traingroups_titledata:\n",
    "    docs = traingroups_titledata[new_group]\n",
    "    for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "        y_train.append(target_id)\n",
    "        groups_train.append(new_group)\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            doc_id_j, title_j, target_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            all_dist.append(len(words.intersection(words_j)))\n",
    "        all_dist = sorted(all_dist, reverse=True)[0:20]\n",
    "        all_dist.append(new_group)\n",
    "        X_train.append(all_dist)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "groups_train = np.array(groups_train)\n",
    "print (X_train.shape, y_train.shape, groups_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для подбора порога используется roc auc \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def cross_val_score(clf, kf, X, y):\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        scores.append(roc_auc_score(y_test, y_pred))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.1,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6981550465599226\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.1,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.69475689337841\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.1,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6981360886703536\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.3,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6970827124647223\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.3,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6965651918521916\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.3,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.698340612660286\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.6,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6981269548911574\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.6,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.698018216314528\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.6,\n",
      "              learning_rate='optimal', loss='hinge', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6981550465599226\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6988795081027646\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='hinge', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6986911775253185\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6986911775253185\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6986100456854091\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='hinge', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6986911775253185\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6989743349583045\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.697925290039969\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='hinge', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6983302969767801\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6983935584776995\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6605446929838835\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='hinge', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.7022518372361178\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.7010832290546939\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6388081650615168\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='hinge', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.7080063326200339\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6837492468474572\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='hinge', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6777670134213009\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='hinge', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6695192122129469\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='hinge',\n",
      "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
      "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6466692329754444\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.1,\n",
      "              learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6828830892389846\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.1,\n",
      "              learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6843844101241578\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.1,\n",
      "              learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6846550492176057\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.3,\n",
      "              learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6815026369334154\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.3,\n",
      "              learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.68302465134237\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.3,\n",
      "              learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6827945421740523\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.6,\n",
      "              learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.686242739069197\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.6,\n",
      "              learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6855020299080681\n",
      "SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.6,\n",
      "              learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6839171310456115\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6956624338207192\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6872123280569539\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6876843320908276\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6957486869093638\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6907275365780648\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6911151301025708\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6906285360429755\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6867852774112043\n",
      "SGDClassifier(alpha=0.01, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6932818019105778\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6969991371692448\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6476269524601463\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.1, learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.7092915056246304\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.6906978069336089\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.7068231728682832\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.3, learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.7021277028036973\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='log', max_iter=100,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.70216770672699\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='log', max_iter=500,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.7100081985117948\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
      "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
      "              l1_ratio=0.6, learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=True)\n",
      "0.7159911630932174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "               early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "               l1_ratio=0.6, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "               n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "               random_state=None, shuffle=True, tol=0.001,\n",
       "               validation_fraction=0.1, verbose=0, warm_start=True),\n",
       " 0.7159911630932174)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from itertools import product\n",
    "res_score = 0\n",
    "res_model = None\n",
    "params = product(\n",
    "    (\"hinge\", \"log\"),\n",
    "    (0.1, 0.01, 0.0001),\n",
    "    (0.1, 0.3, 0.6),\n",
    "    (100, 500, 1000),)\n",
    "for loss, alpha, l1_ratio, max_iter in list(params):\n",
    "    clf = SGDClassifier(loss=loss, l1_ratio=l1_ratio, alpha=alpha, max_iter=max_iter, warm_start=True)\n",
    "    print(clf)\n",
    "    score = np.mean(\n",
    "        cross_val_score(clf=clf, kf=KFold(n_splits=3), X=X_train, y=y_train))\n",
    "    print(score)\n",
    "    if score > res_score:\n",
    "        res_score = score\n",
    "        res_model = clf\n",
    "res_model, res_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score1(clf, kf, X, y, th):\n",
    "    scores = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        scores.append(f1_score(y_test, y_pred >= th))\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:02<00:29,  1.05s/it]/home/nastyboget/media/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      " 17%|█▋        | 5/30 [00:05<00:26,  1.08s/it]/home/nastyboget/media/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      " 80%|████████  | 24/30 [00:25<00:06,  1.09s/it]/home/nastyboget/media/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "100%|██████████| 30/30 [00:32<00:00,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.27586206896551724, 0.6017189361844709)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_score = 0\n",
    "res_th = 0\n",
    "for threshold in tqdm(np.linspace(0.0, 1.0, 30)):\n",
    "    score = cross_val_score1(clf=res_model, kf=KFold(n_splits=3), X=X_train, y=y_train, th=threshold)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "        res_th = threshold\n",
    "res_th, max_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test_groups.csv')\n",
    "testgroups_titledata = {}\n",
    "for i in range(len(test_data)):\n",
    "    new_doc = test_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    text = doc_to_title[doc_id].lower()\n",
    "    title = ' '.join(list(map(stemmer.stemWord, text.split())))\n",
    "    if doc_group not in testgroups_titledata:\n",
    "        testgroups_titledata[doc_group] = []\n",
    "    testgroups_titledata[doc_group].append((doc_id, title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16627, 21) (16627,)\n"
     ]
    }
   ],
   "source": [
    "y_test = []\n",
    "X_test = []\n",
    "groups_test = []\n",
    "for new_group in testgroups_titledata:\n",
    "    docs = testgroups_titledata[new_group]\n",
    "    for k, (doc_id, title) in enumerate(docs):\n",
    "        groups_test.append(new_group)\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            doc_id_j, title_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            all_dist.append(len(words.intersection(words_j)))\n",
    "        all_dist = sorted(all_dist, reverse=True)[0:20]\n",
    "        all_dist.append(new_group)\n",
    "        X_test.append(all_dist)\n",
    "X_test = np.array(X_test)\n",
    "groups_test = np.array(groups_test)\n",
    "print (X_test.shape, groups_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.asarray(res_model.predict(X_test) > res_th, dtype=int)\n",
    "test_data[\"target\"] = pd.Series(y_test)\n",
    "with open(\"result2.csv\", \"w\") as f:\n",
    "    f.write(test_data.to_csv(columns=(\"pair_id\", \"target\"), index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
