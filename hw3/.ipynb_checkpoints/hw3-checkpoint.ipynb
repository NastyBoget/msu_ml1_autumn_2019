{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 25 ноября 2019, 15:00   \n",
    "**Штраф за опоздание:** -2 балла после 15:00 25 ноября, -4 балла после 15:00 2 декабря, -6 баллов после 15:00 9 декабря  -8 баллов после 15:00 16 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0919, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 1 (3 балла)\n",
    "Разберитесь в коде MyDecisionTreeClassifier, который уже частично реализован. Допишите код там, где написано \"Ваш код\". Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn. Точность проверяется на [wine](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) и [Speed Dating Data](https://cloud.mail.ru/public/8nHV/p6J7wY1y1)\n",
    "\n",
    "###### Задание 2 (3 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine и Speed Dating Data. \n",
    "Для этого используем numpy.\n",
    "\n",
    "###### Задание 3 (2 балла)\n",
    "Добавьте функционал, который определяет значения feature importance. Выведите 10 главных фичей под пунктом Задание 4 (уже написано ниже) для MyDecisionTreeClassifier и DecisionTreeClassifier так, чтобы сразу были видны выводы и по MyDecisionTreeClassifier, и по DecisionTreeClassifier. Используем данные Speed Dating Data.\n",
    "\n",
    "###### Задание 4 (2 балла)\n",
    "С помощью GridSearchCV или RandomSearchCV подберите наиболее оптимальные параметры для случайного леса (Выберете 2-3 параметра). Используем данные Speed Dating Data. Задание реализуйте под пунктом Задание 5 (уже написано ниже)\n",
    "\n",
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Невыполнение PEP8 -1 балл\n",
    "2. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw3.ipynb) -1 балл\n",
    "3. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -1 балл\n",
    "4. При оформлении ДЗ нужно пользоваться данным файлом в качестве шаблона. Не нужно удалять и видоизменять написанный код и текст. В противном случае -1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) $ Gini(T) = 1 - \\sum p_i $\n",
    "\n",
    "$ Gini_{split}(T) = \\frac{N_1}{N}Gini(T_1)+\\frac{N_2}{N}Gini(T_2) $\n",
    "\n",
    "$ Gini_{split} = \\frac{L}{N}(1 - \\sum(\\frac{l_i}{L})^2) + \\frac{R}{N}(1 - \\sum(\\frac{r_i}{R})^2) = 1 − \\frac{1}{N}(\\frac{1}{L}\\sum l_i^2 + \\frac{1}{R}\\sum r_i^2) $\n",
    "\n",
    "2) $ Entropy(T) = -\\sum p_i\\log p_i $\n",
    "\n",
    "$ Entropy_{split}(T) = \\frac{N_1}{N}Entropy(T_1) + \\frac{N_2}{N}Entropy(T_2)$\n",
    "\n",
    "$ Enropy_{split} = -\\frac{L}{N}\\sum \\frac{l_i}{L}\\log\\frac{l_i}{L} - \\frac{R}{N}\\sum \\frac{r_i}{R}\\log\\frac{r_i}{R} = -\\frac{1}{N}\\sum (l_i\\log\\frac{l_i}{L} + r_i\\log\\frac{r_i}{R})$\n",
    "\n",
    "3) $ Misclass(T) = 1 - \\max p_i $\n",
    "\n",
    "$ Misclass_{split}(T) = \\frac{N_1}{N}Misclass(T_1) + \\frac{N_2}{N}Misclass(T_2) $\n",
    "\n",
    "$ Misclass_{split} = \\frac{L}{N}(1 - \\max\\frac{l_i}{L}) + \\frac{R}{N}(1 - \\max\\frac{r_i}{R}) = 1 - \\frac{1}{N}(\\max l_i + \\max r_i) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, \n",
    "                 sufficient_share=1.0, criterion='gini', max_features=None):\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "            self.func = self.__gini_gain\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "            self.func = self.__entropy_gain\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "            self.func = self.__misclass_gain\n",
    "        else:\n",
    "            print('invalid criterion name')\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print('invalid max_features name')\n",
    "            raise\n",
    "\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        # l_c массив числа объектов каждого класса слева\n",
    "        # l_s число объектов слева\n",
    "        # r_c массив числа объектов каждого класса справа\n",
    "        # r_s число объектов справа\n",
    "        l_c = l_c.astype('float')\n",
    "        r_c = r_c.astype('float')\n",
    "        return 1 - (np.sum(l_c ** 2) / l_s\n",
    "                    + np.sum(r_c ** 2) / r_s) / (l_s + r_s)\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        return -(np.sum(l_c * np.log(l_c / l_s)) + \\\n",
    "                 np.sum(r_c * np.log(r_c / r_s))) / (l_s + r_s)\n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        return 1 - (np.max(l_c) + np.max(r_c)) / (l_s + r_s)\n",
    "    \n",
    "    def __gini_gain(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        return (1 - np.sum(counts ** 2) / y.size ** 2)\n",
    "\n",
    "    def __entropy_gain(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        return -np.sum(counts / y.size * \n",
    "                                  np.log(counts / y.size))\n",
    "    def __misclass_gain(self, y):\n",
    "        _, counts = np.unique(y, return_counts=True)\n",
    "        return (1 - np.max(counts) / y.size)\n",
    "    \n",
    "    def __importance (self, y, y_l, y_r, index):\n",
    "        self.feature_importances_[index] += (y.size * self.func(y) - \\\n",
    "                                             y_l.size * self.func(y_l) - \\\n",
    "                                             y_r.size * self.func(y_r))\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.sqrt(n_feature))] \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[:int(np.log2(n_feature))] \n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return np.arange(n_feature)\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "        # x - столбец признаков\n",
    "        # y - столбец результатов\n",
    "        # порог - среднее арифметическое двух соседних упорядоченных значений x\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        # индексы, где меняется значение класса\n",
    "        idx_change = np.where(sorted_y[:-1] != sorted_y[1:])[0] + 1\n",
    "        if len(idx_change) == 0:\n",
    "            return np.inf, None\n",
    "        # l_c = np.bincount(y[:idx])\n",
    "        # l_s = y[:idx].size\n",
    "        # r_c = np.bincount(y[idx:])\n",
    "        # r_s = y[idx:].size\n",
    "        err = np.array([self.G_function(np.bincount(sorted_y[:idx]),\n",
    "                                        sorted_y[:idx].size, np.bincount(sorted_y[idx:]), \n",
    "                                        sorted_y[idx:].size) \n",
    "                        for idx in idx_change])\n",
    "        threshold_idx = idx_change[np.argmin(err)]\n",
    "        threshold = (sorted_x[threshold_idx - 1] + sorted_x[threshold_idx]) / 2.0\n",
    "        err = np.min(err)\n",
    "        return err, threshold\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        classes_cnt = np.bincount(y, minlength=self.num_class)\n",
    "        if ((self.max_depth is not None and depth == self.max_depth) or\n",
    "            (self.min_samples_split is not None and \n",
    "             x.shape[0] < self.min_samples_split)):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.argmax(classes_cnt), \n",
    "                                  classes_cnt.astype(float) / classes_cnt.size)\n",
    "            return\n",
    "        gs = np.zeros(x.shape[1])\n",
    "        thresholds = np.zeros(x.shape[1])\n",
    "        idx = self.get_feature_ids(x.shape[1])\n",
    "        for i in idx:\n",
    "            gs[i], thresholds[i] = self.__find_threshold(x[:, i], y)\n",
    "        index = np.argmin(gs)\n",
    "        if np.isnan(thresholds[index]):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.argmax(classes_cnt), \n",
    "                                  classes_cnt.astype(float) / classes_cnt.size)\n",
    "            return\n",
    "        x_l, x_r, y_l, y_r = self.__div_samples(x, y, index, thresholds[index])\n",
    "        if (y_l.shape[0] == 0 or y_r.shape[0] == 0):\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, np.argmax(classes_cnt), \n",
    "                                  classes_cnt.astype(float) / classes_cnt.size)\n",
    "            return\n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, index, thresholds[index])\n",
    "        self.__importance (y, y_l, y_r, index)\n",
    "        self.__fit_node(x_l, y_l, 2 * node_id + 1, depth + 1)\n",
    "        self.__fit_node(x_r, y_r, 2 * node_id + 2, depth + 1)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= y.size\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.25 ms, sys: 3.83 ms, total: 6.08 ms\n",
      "Wall time: 3.58 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 278 ms, sys: 102 µs, total: 278 ms\n",
      "Wall time: 278 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.890993265993266"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8808080808080808"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/speed-dating-experiment/Data.csv', encoding='cp1251')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iid</th>\n",
       "      <th>gender</th>\n",
       "      <th>pid</th>\n",
       "      <th>match</th>\n",
       "      <th>int_corr</th>\n",
       "      <th>samerace</th>\n",
       "      <th>age</th>\n",
       "      <th>field_cd</th>\n",
       "      <th>mn_sat</th>\n",
       "      <th>tuition</th>\n",
       "      <th>...</th>\n",
       "      <th>intel2_1</th>\n",
       "      <th>fun2_1</th>\n",
       "      <th>amb2_1</th>\n",
       "      <th>shar2_1</th>\n",
       "      <th>attr3_1</th>\n",
       "      <th>sinc3_1</th>\n",
       "      <th>fun3_1</th>\n",
       "      <th>intel3_1</th>\n",
       "      <th>amb3_1</th>\n",
       "      <th>temp_totalsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   iid  gender   pid  match  int_corr  samerace   age  field_cd  mn_sat  \\\n",
       "0    1       0  11.0      0      0.14         0  21.0       1.0  -999.0   \n",
       "1    1       0  12.0      0      0.54         0  21.0       1.0  -999.0   \n",
       "2    1       0  13.0      1      0.16         1  21.0       1.0  -999.0   \n",
       "3    1       0  14.0      1      0.61         0  21.0       1.0  -999.0   \n",
       "4    1       0  15.0      1      0.21         0  21.0       1.0  -999.0   \n",
       "\n",
       "   tuition  ...  intel2_1  fun2_1  amb2_1  shar2_1  attr3_1  sinc3_1  fun3_1  \\\n",
       "0   -999.0  ...      15.0    20.0     5.0      5.0      6.0      8.0     8.0   \n",
       "1   -999.0  ...      15.0    20.0     5.0      5.0      6.0      8.0     8.0   \n",
       "2   -999.0  ...      15.0    20.0     5.0      5.0      6.0      8.0     8.0   \n",
       "3   -999.0  ...      15.0    20.0     5.0      5.0      6.0      8.0     8.0   \n",
       "4   -999.0  ...      15.0    20.0     5.0      5.0      6.0      8.0     8.0   \n",
       "\n",
       "   intel3_1  amb3_1  temp_totalsum  \n",
       "0       8.0     7.0          100.0  \n",
       "1       8.0     7.0          100.0  \n",
       "2       8.0     7.0          100.0  \n",
       "3       8.0     7.0          100.0  \n",
       "4       8.0     7.0          100.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:, :97]\n",
    "df = df.drop(['id', 'idg', 'condtn', 'field', 'undergra', 'from', 'zipcode', \n",
    "              'round', 'position', 'positin1', 'order', 'partner',\n",
    "              'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb',\n",
    "              'pf_o_sha', 'dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', \n",
    "              'like_o', 'prob_o', 'met_o', 'sports', 'tvsports', 'exercise', 'dining', \n",
    "              'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv','theater', \n",
    "              'movies', 'concerts', 'music', 'shopping', 'yoga', 'career', 'expnum'], axis=1)\n",
    "\n",
    "df.drop_duplicates('iid').age.isnull().sum()\n",
    "df = df.dropna(subset=['age'])\n",
    "df = df.dropna(subset=['imprelig', 'imprace'])\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(0)\n",
    "pd.get_dummies(df, columns=['field_cd'], prefix='field_cd', prefix_sep='=')\n",
    "df.loc[:, 'mn_sat'] = df.loc[:, 'mn_sat'].str.replace(',', '').astype(np.float).fillna(-999)\n",
    "df.loc[:, 'tuition'] = df.loc[:, 'tuition'].str.replace(',', '').astype(np.float).fillna(-999)\n",
    "df.loc[:, 'income'] = df.loc[:, 'income'].str.replace(',', '').astype(np.float).fillna(-999)\n",
    "df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(0)\n",
    "\n",
    "\n",
    "feat = ['iid', 'wave', 'attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1',\n",
    "        'amb1_1', 'shar1_1']\n",
    "\n",
    "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1',\n",
    "          'shar1_1']].sum(axis=1)\n",
    "\n",
    "df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1',\n",
    "           'shar1_1']] = (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1',\n",
    "                                     'fun1_1', 'amb1_1', 'shar1_1']].T /\n",
    "                          df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "feat = ['iid', 'wave', 'attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1',\n",
    "        'amb2_1', 'shar2_1']\n",
    "\n",
    "temp = df.drop_duplicates(subset=['iid', 'wave']).loc[:, feat]\n",
    "temp.loc[:, 'totalsum'] = temp.iloc[:, 2:].sum(axis=1)\n",
    "df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "                                        'fun2_1', 'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "\n",
    "df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1',\n",
    "           'shar2_1']] = (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1',\n",
    "                                     'fun2_1', 'amb2_1', 'shar2_1']].T /\n",
    "                          df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "for i in [4, 5]:\n",
    "    feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i),\n",
    "            'intel{}_1'.format(i), 'fun{}_1'.format(i),\n",
    "            'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "    if i != 4:\n",
    "        feat.remove('shar{}_1'.format(i))\n",
    "    df = df.drop(feat, axis=1)\n",
    "\n",
    "df = df.drop(['wave'], axis=1)\n",
    "df_male = df.query('gender == 1').drop_duplicates(subset=['iid', 'pid']) \\\n",
    "            .drop(['gender'], axis=1).dropna()\n",
    "\n",
    "df_female = df.query('gender == 0').drop_duplicates(subset=['iid']) \\\n",
    "            .drop(['gender', 'match', 'int_corr', 'samerace'], axis=1).dropna()\n",
    "\n",
    "df_female.columns = df_female.columns + '_f'\n",
    "df_female = df_female.drop(['pid_f'], axis=1)\n",
    "df_pair = df_male.join(df_female.set_index('iid_f'), on='pid', how='inner')\n",
    "df_pair = df_pair.drop(['iid', 'pid'], axis=1)\n",
    "\n",
    "X = df_pair.iloc[:, 1:].values\n",
    "y = df_pair.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=12)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы на Speed Dating Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 212 ms, sys: 0 ns, total: 212 ms\n",
      "Wall time: 211 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тут должен быть код типа %time clf.fit(X_train, y_train)\n",
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 75.4 ms, total: 1min 8s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "# тут должен быть код типа %time my_clf.fit(X_train, y_train)\n",
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы на Speed Dating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5148370981494158"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')\n",
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5679579565056181"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# тут должен быть код типа f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')\n",
    "f1_score(y_pred=my_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_corr      0.011404\n",
      "age_f         0.004699\n",
      "attr1_1       0.004277\n",
      "age           0.003937\n",
      "intel1_1_f    0.003911\n",
      "imprelig_f    0.003747\n",
      "attr2_1_f     0.003502\n",
      "tuition_f     0.003468\n",
      "field_cd_f    0.003363\n",
      "race          0.002924\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(data=my_clf.feature_importances_, \n",
    "        index=df_pair.columns[1:]).sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_corr      0.084241\n",
      "shar2_1       0.028156\n",
      "imprelig_f    0.028017\n",
      "income_f      0.027914\n",
      "sinc1_1_f     0.027194\n",
      "fun1_1_f      0.026482\n",
      "sinc1_1       0.025208\n",
      "intel3_1_f    0.023918\n",
      "career_c_f    0.023423\n",
      "attr3_1       0.022131\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(data=clf.feature_importances_,\n",
    "          index=df_pair.columns[1:]).sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nastyboget/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 14, 'min_samples_split': 6, 'max_depth': 10, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5045826108496407"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parametrs = {\n",
    "    \"min_samples_split\": [i for i in range(2, 15)],\n",
    "    \"max_depth\": [i for i in range(2, 20)],\n",
    "    \"n_estimators\": [i for i in range(1, 15)],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "best_clf = RandomizedSearchCV(RandomForestClassifier(random_state=123), param_distributions=parametrs, n_iter=75)\n",
    "best_clf.fit(X_train, y_train)\n",
    "print(best_clf.best_params_)\n",
    "f1_score(y_pred=best_clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
